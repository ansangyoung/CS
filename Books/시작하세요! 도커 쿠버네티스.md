# 시작하세요! 도커/쿠버네티스  

### 용찬호 지음  

## 01 도커란?  
도커는 리눅스 컨테이너에 여러 기능을 추가함으로써 애플리케이션을 컨테이너로서 좀더 쉽게 사용할 수 있게 만들어진 오픈소스 프로젝트이다.  
도커는 Go 언어로 작성돼 있으며, 기존에 쓰이던 가상화 방법인 가상 머신과는 달리 도커 컨테이너는 성능의 손실이 거의 없어서 차세대 클라우드 인프라 솔루션으로서 많은 개발자들에게 주목받고 있다.  


## 02 도커 엔진  
### 2.1 도커 이미지와 컨테이너  
### 2.1.2 도커 컨테이너  
도커 이미지는 기본적인 리눅스 운영체제부터 각종 애플리케이션, 빅데이터 분석 도구까지 갖가지 종류가 있다.  
이러한 이미지로 컨테이너를 생성하면 해당 이미지의 목적에 맞는 파일이 들어있는 파일시스템과 격리된  
시스템 자원 및 네트워크를 사용할 수 있는 독립된 공간이 생성되고, 이것이 바로 도커 컨테이너가 된다.  
도커 이미지와 컨테이너는 1:N 관계이다.  


### 2.5 도커 데몬  
#### 2.5.1 도커의 구조  
a. 도커 명령어의 위치 확인  
which docker  
-> /usr/bin/docker  
-> 참고: 리눅스의 which 명령어는, 명령어의 파일이 위치한 경로를 출력한다.  
-> 의미: 도커 명령어는 /usr/bin/docker에 위치한 파일을 통해 사용되고 있음. 즉, 컨테이너나 이미지를 다루는 도커 명령어는 /usr/bin/docker에서 실행한다.  

b. 실행 중인 도커 프로세스를 확인  
ps aux | grep docker  
-> USER  PID    %CPU  %MEM  VSZ     RSS    TT  STAT  START  TIME  COMMAND  
   root  20907  0.0   6.7   594500  68872  ?   Ssl   16:28  0:05  /usr/bin/dockerd -H fd://
-> 참고: ps aux 명령어는, 실행 중인 프로세스의 목록을 출력한다. (CPU, MEM사용률, 프로세스 상태 코드 등 확인 가능.)  
-> /usr/bin/dockerd 파일로 도커 엔진의 프로세스를 실행한다. (docker가 아닌 dockerd(도커 데몬)으로 실행하는 이유는, docker 명령어는 클라이언트이기 때문이다.)  

c. 도커의 구조  (클라이언트 + 서버)  
도커 엔진은 외부에서 API 입력을 받아 도커 엔진의 기능을 수행하는데, 도커 프로세스가 실행되어 서버로서 입력을 받을 준비가 된 상태를 "도커 데몬"이라고 한다.  
(데몬: 사용자가 직접적으로 제어하지 않고, 백그라운드에서 돌면서 여러 작업을 하는 프로그램. 일반적으로 프로세스로 실행된다.)  
도커 데몬은 API 입력을 받아 도커 엔진의 기능을 수행하는데, 이 API를 사용할 수 있도록 CLI를 제공하는 것이 "도커 클라이언트"이다.  
실제로 컨테이너를 생성하고 실행하며 이미지를 관리하는 주체는 "도커 서버"로, 도커 데몬 프로세스로서 동작한다.  
-> 즉, 서버로서의 도커 == 도커 데몬 이라고 인지해도 됨.  

d. 도커 데몬을 제어하는 순서  
-> 사용자가 docker로 시작하는 명령어(예를들어, docker version)를 입력하면 도커 클라이언트를 사용하는 것이며, 도커 클라이언트는 입력된 명령어를 로컬에 존재하는 도커 데몬에게 API로서 전달한다.  
-> 도커 데몬은 이 명령어를 파싱하고, 명령어에 해당하는 작업을 수행하며, 수행 결과를 도커 클라이언트에게 반환하고, 사용자에게 결과를 출력한다.  



### 2.5.2 도커 데몬 실행 (2가지 방법) 
도커 데몬은, 일반적으로 service 명령어로 시작, 정지할 수 있다.  
service docker start  
service docker stop  
우분투에서는 도커가 설치되면 자동으로 서비스로 등록되므로, 호스트가 재시작되더라도 자동으로 실행한다.  
그러나, 레드햇 계열의 운영체제는 도커를 설치해도 자동으로 실행되도록 설정되지는 않는다.  
-> 이때, 도커를 자동으로 실행하도록 설정하려면 systemctl enable docker 와 같은 명령어로 docker 서비스를 활성화할 수 있다.  

또한, 서비스를 사용하지 않고 dockerd 입력으로 직접 도커 데몬을 실행할 수 있다.(2.5.1  b.)  
그러나, 실제 운영환경에서는 도커 데몬을 직접 실행하기보다는 service, systemctl 명령어를 통해 리눅스 서비스로서 관리하는 것이 좋다.  
-> 직접 도커 데몬을 실행하면 하나의 터미널을 차지하는 포그라운드 상태로 실행되기 때문이다.  


### 2.5.3 도커 데몬 설정  
#### 2.5.3.1 도커 데몬 제어: -H  
-H 옵션은 도커 데몬의 API를 사용할 수 있는 방법을 추가한다.  
예를들어, -H에 IP 주소와 포트 번호를 입력하면 원격 API인 Docker Remote API로 도커를 제어할 수 있다.  
Remote API는 로컬에 있는 도커 데몬이 아니더라도 제어할 수 있으며, Restful API 형식을 띠고 있으므로 HTTP 요청으로 도커를 제어할 수 있다.  

예를들어, 호스트의 모든 네트워크 인터페이스 카드에 할당된 IP 주소와 2375번 포트로 도커 데몬을 제어함과 동시에, 도커 클라이언트도 사용할 수 있는 방법은 다음과 같다.  
dockerd -H unix:///var/run/docker.sock -H tcp://0.0.0.0:2375  
(도커 클라이언트는 /var/run/docker.sock에 위치한 유닉스 소켓을 통해 도커 데몬의 API를 호출한다.)  
(도커의 Remote API를 사용하는 포트는 보안이 적용돼 있지 않다면 2375번 포트를, 보안이 적용되어 있다면 2376번 포트를 사용하도록 관례상 설정한다.)  
API에 따라서 사용하는 방법이 도커 명령어와 조금씩 다른 부분도 있으므로, HTTP 도구로 직접 API 요청을 전송하기보다는, 특정 언어로 바인딩된 라이브러리를 사용하는 것이 일반적이다.  


#### 2.5.3.2 도커 데몬에 보안 적용: --tlsverify  
도커를 설치하면 기본적으로 보안 연결이 설정돼 있지 않다. 이는 도커 클라이언트, Remote API를 사용할 때 별도의 보안이 적용되지 않음을 의미한다.  
보안이 적용되어 있지 않으면 Remote API를 위해 바인딩된 IP주소와 포트 번호만 알면 도커를 제어할 수 있다.  
도커 데몬에 TLS보안을 적용하거나 도커 클라이언트와 Remote API 클라이언트가 인증되지 않으면 도커 데몬을 제어할 수 없도록 설정할 수 있다.  
TLS(Transpot Layer Security): 인터넷에서 정보를 암호화해서 송수신하는 프로토콜로 SSL에 기반한 기술이다.  


#### 2.5.3.3 도커 스토리지 드라이버 변경: --storage-driver  
도커는 특정 스토리지 백엔드 기술을 사용해 도커 컨테이너와 이미지를 저장하고 관리한다.  
일부 운영체제는 도커를 설치할 때 기본적으로 사용하도록 설정된 스토리지 드라이버가 있는데, 우분투같은 데비안 계열 운영체제는 overlay2를, 구 버전의 CentOS와 같은 운영체제는 devicemapper를 사용하는 것이 대표적인 예이다.  
이는 docker info 명령어로 확인할 수 있다.  
docker info | grep "Storage Driver"  
-> Storage Driver: overlay2  

스토리지 드라이버의 원리  
도커 스토리지 드라이버는 CoW, RoW를 지원해야 한다.  
스냅숏: 원본 파일은 읽기 전용으로 사용하되, 이 파일이 변경되면 새로운 공간을 할당  
이미지: 읽기 전용 파일로 사용하며, 각 스냅숏에 해당  
컨테이너: 이미지 위에 얇은 컨테이너 레이어를 생성함으로써 컨테이너의 고유한 공간을 생성. 스냅숏을 사용하는 변경점이다. 이전 이미지에서 변경된 사항이 저장되어 있다.  
컨테이너를 이미지로 만들면, 변경된 사항이 스냅샷으로 생성된다.  

CoW (Copy-on-Write)  
스냅숏의 파일에 쓰기 작업을 수행할 때, 스냅숏 공간에 원본 파일을 복사한 뒤, 쓰기 요청을 반영한다.  
이 과정에서 복사하기 위해 파일을 읽는 작업 한 번, 파일을 스냅숏 공간에 쓰고 변경된 사항을 쓰는 작업 한 번, 총 2번의 쓰기 작업이 일어나므로 오버헤드가 발생한다.  
Row (Redirect-on-Write)  
파일을 스냅숏 공간에 복사하는 것이 아니라, 스냅숏에 기록된 원본 파일은 스냅숏 파일로 묶은 뒤, 변경된 사항을 새로운 장소에 할당받아 덮어쓰는 형식이다.  
즉, 스냅숏 파일은 그대로 사용하되, 새로운 블록은 변경 사항으로써 사용하는 것이다.  


#### 2.5.3.4 컨테이너 저장 공간 설정  
컨테이너 내부에서 사용되는 파일시스템의 크기는 도커가 사용하고 있는 스토리지 드라이버에 따라 조금씩 다르다.  
예를들어, AUFS나 overlay2 등의 스토리지 드라이버를 사용하도록 설정되어 있다면, 컨테이너는 호스트와 저장 공간의 크기를 공유한다.  
devicemapper와 같은 드라이버를 사용하고 있다면, 기본적으로 컨테이너는 10GB의 저장 공간을 할당 받는다.  

### 2.5.4 도커 데몬 모니터링  
#### 2.5.4.1 도커 데몬 디버그 모드  
도커 데몬을 디버그모드로 실행하면, Remote API의 입출력뿐만 아니라, 로컬 도커 클라이언트에서 오가는 모든 명령어를 로그로 출력한다.  
디버그모드는 도커 데몬을 실행할 때 -D 옵션을 추가해서 사용할 수 있다.  
그러나 로그에는 원하지 않는 정보까지 너무 많이 출력되며, 도커 데몬을 포그라운드 상태로 실행해야 한다는 단점이 있다.  


#### 2.5.4.2 events, stats, system df 명령어  
events  
도커 자체가 제공하는 기능이며, 도커가 기본으로 제공하는 명령어이다.  
docker events 또는 docker system events로 입력하면, "도커 데몬에 어떤 일이 일어나고 있는지를" 실시간 스트림 로그로 보여준다.  
다음 예는 이미지에 관한 로그만 출력하도록 설정하여 이미지에 관련된 명령어만 출력할 수 있다.  
docker events --filter 'type=image'  

stats  
실행중인 모든 컨테이너의 "자원 사용량"을 스트림으로 출력한다. CPU, 메모리 제한 및 사용량, 네트워크 입출력(I/O), 블록 입출력(하드웨어 입출력) 정보를 출력한다.  
CONTAINER     ID NAME         CPU %  MEM USAGE / LIMIT     MEM %  NET I/O   BLOCK I/O        PIDS  
42974ae6b3de  k8s_jenkins_..  0.06%  663.1MiB  / 7.007GiB  9.24%  0B / 0B   129MB / 3.36MB   39  

system df  
도커에서 사용하고 있는 "이미지, 컨테이너, 로컬 볼륨의 총 개수 및 사용 중인 개수, 크기, 삭제함으로 확보 가능한 공간"을 출력한다.  
TYPE    TOTAL  ACTIVE  SIZE     RECLAIMABLE  
Images  128    21      49.99GB  41.19GB (82%)  


#### 2.5.4.3 CAdvisor  
구글이 만든 컨테이너 모니터링 도구로, 컨테이너로서 간단히 설치할 수 있고 컨테이너별 실시간 자원 사용량 및 도커 모니터링 정보 등을 시각화해서 보여준다.  
오픈소스로서 깃허브에서 소스코드로 사용할 수 있으며, 도커 허브에서 도커 이미지로도 배포되고 있다.  


### 2.5.5 Remote API 라이브러리를 이용한 도커 사용  
-H 옵션을 원격의 도커 데몬을 제어하기 위해 사용하는 것도 좋은 방법이다.  
컨테이너 애플리케이션이 수행해야 할 작업이 많거나 애플리케이션 초기화 등에 복잡한 과정이 포함되어 있다면, 도커를 제어하는 라이브러리를 사용해 이를 좀 더 쉽게 해결할 수 있다.  
즉, 도커를 제어하고 싶을 경우 일일이 Remote API에 대한 요청을 소스코드로 제작할 필요 없이, 이미 Remote API를 래핑해서 사용하기 쉽게 만들어 놓은 라이브러리를 이용할 수 있다.  


## 03 도커 스웜  
### 3.1 도커 스웜을 사용하는 이유  
새로운 서버나 컨테이너가 추가됐을 때 이를 발견하는 작업부터 어떤 서버에 컨테이너를 할당할 것인가에 대한 스커줄러와 로드밸런서 문제, 클러스터 내의 서버가 다운됐을 때 고가용성을 어떻게 보장할지 등이 문제로 남아있다.  
이러한 문제를 해결하는 여러 솔루션을 오픈소스로 활용할 수 있다.  
이 가운데 대표적인 것이 도커에서 공식적으로 제공하는 도커 스웜과 스웜모드이다.  


### 3.2 스웜 클래식과 도커 스웜 모드  
스웜 클래식과 스웜 모드는 여러 대의 도커 서버를 하나의 클러스터로 만들어 컨테이너를 생성하는 여러 기능을 제공한다.  
두가지 종류가 있는데, 첫 번째는 도커 버전 1.6 이후부터 사용할 수 있는 컨테이너로서의 스웜(스웜 클래식)이고, 두 번째는 도커 버전 1.12 이후부터 사용할 수 있는 도커 스웜모드(스웜 모드)이다.  
스웜 클래식은 여러 대의 도커 서버를 하나의 지저머에서 사용하도록 단일 접근점을 제공한다면,  
스웜 모드는 마이크로서비스 아키텍처의 컨테이너를 다루기 위한 클러스터링 기능에 초점을 맞추고 있다.  
일반적으로는 스웜 모드를 더 많이 사용한다.  


### 3.3 스웜모드  
docker info 명령어를 통해 도커 엔진의 스웜 모드 클러스터 정보를 확인할 수 있다.  
docker info | grep Swarm  
-> Swarm: inactive  

### 3.3.1 도커 스웜 모드의 구조  
스웜 모드는 매니저 노드와 워커 모드로 구성돼 있따. 워커 노드는 실제로 컨테이너가 생성되고 관리되는 도커 서버이고, 매니저 노드는 워커 노드를 관리하기 위한 도커 서버이다.  

### 3.3.2 도커 스웜 모드 클러스터 구축  
### 3.3.3 스웜 모드 서비스  
#### 3.3.3.1 스웜 모드 서비스 개념  
스웜 모드에서 제어하는 단위는 컨테이너가 아닌 서비스이다. 컨테이너들은 태스크라고 한다.  


## 04 도커 컴포즈  
### 4.1 도커 컴포즈를 사용하는 이유  
도커 컴포즈는 컨테이너를 이용한 서비스의 개발과 CI를 위해 여러 개의 컨테이너를 하나의 프로젝트로서 다룰 수 있는 작업 환경을 제공한다.  


### 4.4 도커 학습을 마치며: 도커와 컨테이너 생태계  
사실 도커 데몬은 컨테이너가 아니다.  
실제로 컨테이너 프로세스라고 부를 수 있을 만한 것은 dockerd가 아닌 runC이다.  
컨테이너에 1:1로 매칭되는 런타임 역할을 runC가 담당한다.  
그리고 여러 개의 runC 컨테이너 프로세스 및 이미지를 관리하는 주체가 바로 containerd(컨테이너-디)이다.  
도커 엔진(dockerd 프로세스)은 containerd와 통신해 runC를 사용할 수 있도록 하는 엔드유저용 도구에 불과하다.  


## 06 쿠버네티스 시작하기  
### 6.1 쿠버네티스를 시작하기 전에  
쿠버네티스는 대부분의 리소스를 '오브젝트'라고 불리는 형태로 관리한다.  
(스웜모드의 서비스도 컨테이너 리소스의 집합을 정의한 것이기 때문에 일종의 오브젝트라고 볼 수 있다.)  
쿠버네티스는 컨테이너의 집합(pods), 컨테이너의 집합을 관리하는 컨트롤러(Replica Set), 사용자(Service Account), 노드(Node)등을 하나의 오브젝트로 사용할 수 있다.  
1. 쿠버네티스에서 사용할 수 있는 오브젝트 확인   
``kubectl api-resources``  
2. 특정 오브젝트의 간단한 설명 확인  
``kubectl explain pod``  

쿠버네티스도 YAML 파일로 컨테이너 리소스를 생성하거나 삭제할 수 있다.  
(쿠버네티스에서 YAML 파일의 용도는 컨테이너뿐만 아니라, 거의 모든 리소스 오브젝트들에 사용될 수 있다.)  

쿠버네티스 노드의 역할은 크게 마스터와 워커로 나뉘어 있다.  
마스터 노드는 쿠버네티스가 제대로 동작할 수 있게 클러스터를 관리하는 역할을 담당한다.  
워커 노드에는 애플리케이션 컨테이너가 생성된다.  
마스터 노드에는 API 서버(kube-apiserver), 컨트롤러 매니저(kube-controller-manager), 스케줄러(kube-scheduler), DNS(coreDNS) 서버 등이 컨테이너로 실행되며,  
모든 노드에서는 오버레이 네트워크 구성을 위해 프락시(kube-proxy)와 네트워크 플러그인(calico, fiannel 등)이 실행된다.  

쿠버네티스 클러스터 구성을 위해 kubelet이라는 에이전트가 모든 노드에서 실행된다.  
kubelet은 컨테이너의 생성, 삭제뿐만 아니라 마스터와 워커 노드 간의 통신 역할을 함께 담당하는 중요한 에이전트로, 모든 노드에서 기본적으로 실행된다.  


### 6.2 포드(Pod): 컨테이너를 다루는 기본 단위  
### 6.2.1 포드 사용하기  
쿠버네티스에서 컨테이너 애플리케이션의 기본 단위를 포드라고 부르며, 포드는 1개 이상의 컨테이너로 구성된 컨테이너의 집합이다.  
1개의 포드에는 여러 개의 컨테이너가 존재할 수도 있다. 

Nginx 컨테이너로 구성된 포드를 직접 생성하기 위한 nginx-pod.yaml  
```  
apiVersion: v1  
kind: Pod  
metadata:  
  name: my-nginx-pod  
spec:  
  containers:  
  - name: my-nginx-container  
    image: nginx:latest  
    ports:  
    - containerPort: 80  
      protocol: TCP  
```

1. apiVersion: YAML 파일에서 정의한 오브젝트의 API 버전  
2. kind: 이 리소스의 종류를 나타내며, 생성하려고 하는 것을 입력한다. 
(kind 항목에서 사용할 수 있는 리소스 오브젝트 종류는  ``kubectl api-resources`` 명령어 결과, KIND 항목에서 확인할 수 있다.)  

3. metadata: 라벨, 주석, 이름 등과 같은 리소스의 부가 정보들을 입력한다. 예시에서는 name 항목에서 포드의 고유한 이름을 my-nginx-pod로 설정.  
4. spec: 리소스를 생성하기 위한 자세한 정보를 입력한다.  
예시에서는 포드에서 실행될 컨테이너 정보를 정의하는 containers 항목을 작성한 뒤, 하위 항목인 image에서 사용할 도커 이미지를 지정.  
(name 항목에서는 컨테이너의 이름, ports 항목에서는 Nginx 컨테이너가 사용할 포트인 80)  

작성한 YAML 파일은 ``kubectl apply -f <xx.yaml>`` 명령어로 쿠버네티스에 생성할 수 있다.  
``kubectl get <오브젝트이름>``을 사용하면 특정 오브젝트 목록을 확인할 수 있다.  
(``kubectl get pods`` 명령어는 현재 쿠버네티스에 존재하는 포드의 목록을 출력한다.)  

쿠버네티스 외부 또는 내부에서 접근하려면 서비스라고 하는 쿠버네티스 오브젝트를 따로 생성해야 한다.  
서비스 오브젝트 없이 IP만으로 Nginx 포드에 접근하려면,  
클러스터의 노드 중 하나에 접속한 뒤 Nginx 포드의 IP로 HTTP 요청을 전송하여, 정상적으로 실행 중인지 확인할 수 있다.  

kubectl exec 명령으로 포드의 컨테이너에 명령어를 전달할 수 있다.  
``kubtcl exec -it my-nginx-pod bash``  
-> my-nginx-pod에서 배치 셸을 실행하되, -it 옵션으로 셸을 유지함.  

kubectl logs 명령어로 포드의 로그를 확인할 수있다.  
``kubectl logs my-nginx-pod``  
-> Nginx 서버에 접근했던 기록 확인.  

쿠버네티스의 오브젝트는 kubectl delete -f 명령어로 쉽게 삭제할 수 있다.  
``kubectl delete -f nginx-pod.yaml``  
-> nginx-pod.yaml에 정의된 Nginx 포드를 삭제.  


### 6.2.2 포드 vs 도커 컨테이너  
포드는 컨테이너 IP 주소를 가지고 있어 쿠버네티스 클러스터 내부에서 접근할 수 있고,  
``kubectl exec`` 명령어로 포드 컨테이너 내부로 들어갈 수도 있으며,  
``kubectl logs`` 명령어로 포드의 로그를 확인할 수도 있다.  
이 기능들만 놓고 본다면 docker run으로 생성한 단일 nginx 컨테이너와 크게 다르지 않아 보인다.  

쿠버네티스가 포드를 사용하는 이유는 컨테이너 런타임의 인터페이스 제공 등 여러 가지가 있지만,  
여러 리눅스 네임스페이스를 공유하는 여러 컨테이너들을 추상화된 집합으로 사용하기 위해서다.  

Nginx 포드에 새로운 우분투 컨테이너를 추가한다면, 
우분투 컨테이너가 Nginx 서버를 실행하고 있지 않은데도, 우분투 컨테이너의 로컬호스트에서 Nginx 서버로 접근이 가능하다.  
이는 포드 내의 컨테이너들이 네트워크 네임스페이스 등과 같은 리눅스 네임스페이스를 공유해 사용하기 때문이다.  
(컨테이너 네트워크 타입은 네트워크 네임스페이스를 컨테이너 간에 공유해 사용할 수 있도록 설정하기 때문에 여러 개의 컨테이너가 동일한 네트워크 환경을 가지게 된다.)  

1개의 포드에 포함된 컨테이너들은 여러 개의 리눅스 네임스페이스를 공유한다.  
즉, 포드 내부의 컨테이너들은 네트워크와 같은 리눅스 네임스페이스를 공유한다.  


### 6.2.3 완전한 애플리케이션으로서의 포드  
실제 쿠버네티스 환경에서는 1개의 컨테이너로 구성된 포드를 사용하는 경우가 많다.  
하나의 포드는 하나의 완전한 애플리케이션이기 때문에, 하나의 포드에 2개의 컨테이너가 정의되는 것은 바람직하지 않다.  

그러나 Nginx 컨테이너가 실행되기 위해 부가적인 기능을 필요로 한다면,  
주 컨테이너를 Nginx로 하되, 기능 확장을 위한 추가 컨테이너를 함께 포드에 포함시킬 수 있다.  
이렇게 포드에 정의된 부가적인 컨테이너를 사이드카(sidecar) 컨테이너라고 부르며, 사이드카 컨테이너는 포드 내의 다른 컨테이너와 네트워크 환경 등을 공유하게 된다.  
(포드에 포함된 컨테이너들은 모두 같은 워커 노드에서 함께 실행된다.)  
이러한 구조 및 원리에 따라 포드에 정의된 여러 개의 컨테이너는 하나의 완전한 애플리케이션으로서 동작하게 된다.  


### 6.3 레플리카셋(Replica Set): 일정 개수의 포드를 유지하는 컨트롤러  
### 6.3.1 레플리카셋을 사용하는 이유  
``kubectl delete`` 명령어로 포드를 삭제하면, 그 포드의 컨테이너 또한 삭제된 뒤 쿠버네티스에서 영원히 사라지게 된다.  
실제로 외부 사용자의 요청을 처리해야 하는 마이크로서비스 구조의 포드라면, 여러 개의 동일한 컨테이너를 생성한 뒤 외부 요청이 각 컨테이너에 적절히 분배될 수 있어야 한다.  

기본 단위가 포드이기 때문에, 동일한 여러 개의 포드를 생성해 외부 요청을 각 포드에 분배하는 방식을 사용해야 한다.  
동일한 여러 개의 포드를 생성하는 가장 간단한 방법은 다른 이름을 가지는 여러 개의 포드를 직접 만드는 방식이다.  
이 방식은 적절하지 않은데, 일일이 정의하는 것은 비효율적이며, 포드에 접근하지 못할 때 직접 포드를 삭제하고 다시 생성하지 않는 한 해당 포드는 다시 복구되지 않는다.  

이러한 포드만 YAML 파일에 정의해 사용하는 방식은 여러 가지 한계점이 있으므로, 레플리카셋이라는 쿠버네티스 오브젝트를 함께 사용하는 것이 일반적이다.  
레플리카셋은 정해진 수의 동일한 포드가 항상 실행되도록 관리하며,  
노드 장애 등의 이유로 포드를 사용할 수 없다면 다른 노드에서 포드를 다시 생성한다.  
따라서 동일한 Nginx 포드를 안정적으로 여러 개 실행할 수도 있고, 워크 노드에 장애가 생기더라도 정해진 개수의 포드를 유지할 수 있다.  


### 6.3.2 레플리카셋 사용하기  
Nginx 포드를 생성하는 레플리카셋을 만들기 위한 replicaset-nginx.yaml 파일  

``` 
apiVersion: apps/v1  
kind: ReplicaSet  
metadata:  
  name: replicaset-nginx  
spec:  
  replicas: 3  
  selector:  
    matchLabels:  
      app: my-nginx-pods-label  
  template:  
    metadata:  
      name: my-nginx-pod  
      labels:  
        app: my-nginx-pods-label  
    spec:  
      containers:  
      - name: nginx  
        image: nginx:latest  
        ports:  
        - containerPort: 80  
```

1. spec.replicas: 동일한 포드를 몇 개 유지시킬 것인지 설정  
예시에서는 레플리카셋은 3개의 포드를 새롭게 생성한다.  

2. spec.template: 포드를 생성할 때 사용할 템플릿을 정의. 어떠한 포드를 어떻게 생성할 것인지를 명시하며, 보통 포드 스펙, 또는 포드 템플릿이라고 한다.  

레플리카셋을 삭제하려면 ``kubectl delete -f`` 명령어를 사용하거나, 
``kubectl delete rs`` 명령어를 사용하면 된다.  
(replicasets 대신 rs를 사용할 수 있다.)  
레플리카셋에 의해 생성된 포드 또한 함께 삭제된다.  


### 6.3.3 레플리카셋의 동작 원리  
실제로는 레플리카셋은 포드와 연결돼 있지 않고, 느슨한 연결을 유지하고 있으며, 이러한 느슨한 연결은 포드와 레플리카셋의 정의 중 라벨 셀렉터를 이용해 이뤄진다.  

라벨은 쿠버네티스 리소스의 부가적인 정보를 표현할 수 있을 뿐만 아니라, 서로 다른 오브젝트가 서로를 찾아야 할 때 사용되기도 한다.  
예를들어 레플리카셋은 spec.selector.matchLabel에 정의된 라벨을 통해 생성해야 하는 포드를 찾는다.  
즉, app: my-nginx-pods-label 라벨을 가지는 포드의 개수가 replica 항목에 정의된 숫자인 3개와 일치하지 않으면, 포드를 정의하는 포드 템플릿 항목의 내용으로 포드를 생성한다.  
예를들어, app: my-nginx-pods-label 라벨을 가지는 포드를 미리 생성해 놓은 다음 레플리카셋을 생성한다면, 이미 존재하는 포드를 제외하고 생성된다.  

수동으로 생성한 포드를 삭제할 경우, 라벨셀렉터와 일치하는 포드가 줄어들었기 때문에, 새로운 포드를 생성한다.  

레플리카셋이 생성해 놓은 포드의 라벨을 삭제할 경우에도 새로운 포드를 생성한다.  
라벨을 삭제한 포드는 레플리카셋의 selector.matchLabel 항목의 값과 더 이상 일치하지 않으므로 레플리카셋에 의해 관리되지 않으며,  
직접 수동으로 생성한 포드와 동일한 상태가 된다.  
따라서 레플리카셋을 삭제해도 이 포드는 삭제되지 않으며, 직접 수동으로 삭제해야 한다.  

레플리카셋의 목적은 포드를 생성하는 것이 아닌 일정 개수의 포드를 유지하는 것이다.  


### 6.3.4 레플리케이션 컨트롤러 vs 레플리카셋  
이전 버전의 쿠버네티스에서는 레플리카셋이 아닌 레플리케이션 컨트롤러(Replication Controller)라는 오브젝트를 통해 포드의 개수를 유지했다.  
쿠버네티스의 버전이 올라감에 따라 레플리케이션 컨트롤러는 더 이상 사용되지 않으며(deprecated), 그 대신 레플리카셋이 사용되고 있다.  
차이 중 하나는 표현식(matchExpression) 기반의 라벨 셀렉터를 사용할 수 있다.  
```  
selector:  
    matchExpresssions:  
        - key: app  
          value:  
              - my-nginx-pods-label  
              - your-nginx-pods-label  
          operator: In  
```
 
위 예시는 키가 app인 라벨을 가지고 있는 포드들 중에서, values 항목에 정의된 값들이 존재하는 포드들을 대상으로 하겠다는 의미이다.  
(각 라벨을 가지는 포드 또한 레플리카셋의 관리하에 놓이게 된다.)  
operator에는 In 외에도 NotIn, Exists 등을 사용할 수 있다. 


## 08 인그레스(Ingress)  
실제 운영 환경에서 쿠버네티스를 사용하려면 많은 기능이 필요하다. 예를 들어 네트워크 7계층에서 가상 호스트를 이용해 서비스 요청을 처리하거나, 애플리케이션의 영속적인 데이터를 보관하기 위한 외부 볼륨이 필요할 수도 있다. 또한 여러 명의 개발자 또는 애플리케이션이 함께 사용하는 쿠버네티스 클러스터에서는 보안을 위해 반드시 권한을 관리해야 하며, 특정 포드가 컴퓨팅 자원을 독차지하는 것을 막기 위해 메모리, CPU 사용량의 제한을 위한 체계적인 시스템도 필요하다.  

인그레스는 일반적으로 외부에서 내부로 향하는 것을 지칭한다. 예를들어 인그레스 트래픽은 외부에서 서버로 유입되는 트래픽을 의미하며, 인그레스 네트워크는 인그레스 트래픽을 처리하기 위한 네트워크를 의미한다. 인그레스는 외부요청을 어떻게 처리할 것인지 네트워크 7계층 레벨에서 정의하는 쿠버네티스 오브젝트이다.  

인그레스 오브젝트가 담당할 수 있는 기본적인 기능  
1. 외부 요청의 라우팅: /apple, /apple/red 등과 같이 특정 경로로 들어온 요청을 어떠한 서비스로 전달할지 정의하는 라우팅 규칙을 설정할 수 있다.  
2. 가상 호스트 기반의 요청 처리: 같은 IP에 대해 다른 도메인 이름으로 요청이 도착했을 때, 어떻게 처리할 것인지 정의할 수 있다.  
3. SSL/TLS 보안 연결 처리: 여러 개의 서비스로 요청을 라우팅할 때, 보안 연결을 위한 인증서를 쉽게 적용할 수 있다.  


### 8.1 인그레스를 사용하는 이유  
애플리케이션이 3개의 디플로이먼트로 생성돼 있을 때, 각 디플로이먼트를 외부에 노출해야 한다면 NodePort 또는 LoadBalancer 타입의 서비스 3개를 생성하는 방법이 있다. 각 디플로이 먼트에 대응하는 서비스를 하나씩 연결해주는 방식인데, 서비스마다 세부적인 설정을 할 때 추가적인 복잡성이 발생한다. SSL/TLS 보안 연결, 접근 도메인 및 클라이언트 상태에 기반한 라우팅 등을 구현하려면 각 서비스와 디플로이먼트에 대해 일일이 설정을 해야 하기 때문이다. 인그레스 오브젝트를 사용하면 URL 엔드포인트를 단 하나만 생성함으로써 이러한 번거로움을 쉽게 해결할 수 있다. 라우팅 정의나 보안 연결 등과 같은 세부 설정은 서비스와 디폴로이먼트가 아닌 인그레스에 의해 수행된다. 즉, 외부 요청에 대한 처리 규칙을 쿠버네티스 자체의 기능으로 편리하게 관리할 수 있다.  


### 8.2 인그레스의 구조  
``kubectl get ingress`` 명령어로 인그레스의 목록을 확인할 수 있다.  
``-> (처음사용시)No resources found in default namespace.``  

YAML 파일로 인그레스를 정의해서 생성  
```
apiVersion: networking.k8s.io/v1beta1  
kind: Ingress  
metadata:  
  name: ingress-example  
  annotations:  
    nginx.ingress.kubernetes.io/rewrite-target: /  
    kubernetes.io/ingress.class: "nginx"  
spec:  
  rules:  
  - host: alicek106.example.com                  # [1]  
    http:  
      paths:  
      - path: /echo-hostname                     # [2]  
        backend:  
          serviceName: hostname-service          # [3]  
          servicePort: 80  
```
(apiVersion은 쿠버네티스 오브젝트나 API의 종류 및 성숙도를 나타내는 일종의 카테고리이다.)  
1. host: 해당 도메인 이름으로 접근하는 요청에 대해서 처리 규칙을 적용한다.  
위 예시에서는 alicek106.example.com이라는 도메인으로 접근하는 요청만 처리하지만, 여러 개의 host를 정의해 사용할 수도 있다.  
2. path: 해당 경로에 들어온 요청을 어느 서비스로 전달할 것인지 정의한다.  
위 예시에서는 /echo-hostname이라는 경로의 요청을 backend에 정의된 서비스로 전달한다.  
여러 개의 path를 정의해 경로를 처리할 수도 있다.  
3. serviceName, servicePort: path로 들어온 요청이 전달될 서비스와 포트이다.  
위 예시에서는 /echo-hostname이라는 경로로 들어온 요청을 hostname-service 서비스의 80 포트로 전달한다.  

ingress-example.yaml 파일로 인그레스를 생성한 다음, 인그레스의 목록을 확인  
``kubectl apply -f ingress-example.yaml``  

이슈  
https://kubernetes.io/docs/reference/using-api/deprecation-guide/
...
Ingress  
The extensions/v1beta1 and networking.k8s.io/v1beta1 API versions of Ingress is no longer served as of v1.22.  
...

``kubectl apply -f ingress-example2.yaml``  
```
apiVersion: networking.k8s.io/v1  
kind: Ingress  
metadata:  
  name: ingress-example2  
  annotations:  
    nginx.ingress.kubernetes.io/rewrite-target: /  
    kubernetes.io/ingress.class: "nginx"  
spec:  
  rules:  
  - host: alicek106.example.com                 # [1]  
    http:  
      paths:  
      - path: /echo-hostname                    # [2]  
        pathType: Prefix  
        backend:  
          service:  
            name: hostname-service              # [3]  
            port:  
              number: 80  
```

```
C:\kubernetes\chapter8>kubectl apply -f ingress-example2.yaml  
ingress.networking.k8s.io/ingress-example2 created  

C:\kubernetes\chapter8>  
C:\kubernetes\chapter8>  
C:\kubernetes\chapter8>kubectl get ingress  
NAME               CLASS    HOSTS                   ADDRESS   PORTS   AGE  
ingress-example2   <none>   alicek106.example.com             80      10s  
```
인그레스를 생성했지만, 아무것도 일어나지 않는다. 인그레스는 단지 요청을 처리하는 규칙을 정의하는 선언적인 오브젝트일 뿐, 외부 요청을 받아들일 수 있는 실제 서버가 아니기 때문이다.  
인그레스는 인그레스 컨트롤러라고 하는 특수한 서버에 적용해야만 그 규칙을 사용할 수 있다. 즉, 실제로 외부 요청을 받아들이는 것은 인그레스 컨트롤러 서버이며, 이 서버가 인그레스 규칙을 로드해 사용한다.  

인그레스 컨트롤러 서버는 여러 종류가 있으며, 대표적으로는 쿠버네티스 커뮤니티에서 활발히 사용되고 있는 Nginx 웹 서버 인그레스 컨트롤러가 있다. 쿠버네티스에서 공식적으로 개발되고 있기 때문에 설치를 위한 YAML 파일을 공식 깃허브 저장소에서 직접 내려받을 수 있다.  

Nginx 인그레스 컨트롤러와 관련된 모든 리소스를 한번에 설치할 수 있는 명령어  
```
kubectl apply -f \  
https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v0.35.0/deploy/static/provider/aws/deploy.yaml  
```  

ingress-nginx 네임스페이스의 디플로이먼트와 포드를 확인하여 Nginx 웹 서버 생성돼어 있음을 확인  
``kubectl get pods,deployment -n ingress-nginx``  

외부에서 Nginx 인그레스 컨트롤러에 접근하기 위한 서비스 생성 확인  
``kubectl get svc -n ingress-nginx``  

인그레스의 종착점이 될 테스트용 디플로이먼트와 서비스를 생성해 최종적으로 인그레스의 동작 여부 확인  
``kubectl apply -f hostname-deployment.yaml``  
``kubectl apply -f hostname-service.yaml``  
``kubectl get pods,services``  
```
C:\kubernetes\chapter8>kubectl get pods,services  
NAME                                       READY   STATUS             RESTARTS   AGE  
pod/hostname-deployment-78db489b5c-fzbj9   1/1     Running            0          31m  
pod/hostname-deployment-78db489b5c-gkxr7   1/1     Running            0          32m  
pod/hostname-deployment-78db489b5c-jpr7l   1/1     Running            0          31m  

NAME                             TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE  
service/hostname-service         ClusterIP   10.109.75.105   <none>        80/TCP     32m  
```
인그레스 컨트롤러에 의해 요청이 최종적으로 도착할 디플로이먼트의 서비스는 어떤 타입이든지 상관은 없다.  
다만 굳이 외부에 서비스를 노출할 필요가 없다면, ClusterIP 타입을 사용하는 것이 좋다.  
위 예시에서는 hostname-service라는 이름의 서비스는 ClusterIP타입으로 생성했다.  

Nginx 인그레스 컨트롤러의 /echo-hostname으로 요청을 전송  
- NodePort 타입으로 서비스를 생성했을 경우  
```
kubectl describe pods hostname-deployment-78db489b5c-fzbj9  
curl --resolve alicek106.example.com:31000:172.17.0.4 alicek106.example.com:31000/echo-hostname  
```


인그레스를 사용하는 방법  
1. 공식 깃허브에서 제공되는 YAML 파일로 Nginx 인그레스 컨트롤러를 생성한다.  
2. Nginx 인그레스 컨트롤러를 외부로 노출하기 위한 서비스를 생성한다.  
3. 요청 처리 규칙을 정의하는 인그레스 오브젝트를 생성한다.  
- 인그레스를 생성하면 인그레스 컨트롤러는 자동으로 인그레스를 로드해 Nginx 웹 서버에 적용한다. 이를 위해 Nginx 인그레스 컨트롤러는 항상 인그레스 리소스의 상태를 지켜보고 있으며, 기본적으로 모든 네임스페이스의 인그레스 리소스를 읽어와 규칙을 적용한다.  
4. Nginx 인그레스 컨트롤러로 들어온 요청은 인그레스 규칙에 따라 적절한 서비스로 전달된다.  
- 테스트용 인그레스에서는 /echo-hostname이라는 경로로 들어온 요청을 hostname-service라는 서비스의 80 포트로 전달했다. 요청이 실제로 hostname-service라는 서비스로 전달되는 것은 아니며, 서비스에 의해 생성된 엔드포인트로 요청을 직접 전달한다.  
``kubectl get endpoints``


### 8.3 인그레스의 세부 기능: annotation을 이용한 설정  
인그레스는 YAML 파일의 주석 항목을 정의함으로써 다양한 옵션을 사용할 수 있다.  
```
apiVersion: networking.k8s.io/v1beta1  
kind: Ingress  
metadata:  
  name: ingress-example  
  annotations:  
    nginx.ingress.kubernetes.io/rewrite-target: /  # [2] hostname-service의 /로 전달된다.  
    kubernetes.io/ingress.class: "nginx"  
spec:  
  rules:  
  - host: alicek106.example.com  
    http:  
      paths:  
      - path: /echo-hostname                     # [1] /echo-hostname 경로로 들어온 요청을  
        backend:  
          serviceName: hostname-service  
          servicePort: 80  
```
kubernetes.io/ingress.class는 해당 인그레스 규칙을 어떤 인그레스 컨트롤러에 적용할 것인지를 의미한다.  
nginx.ingress.kubernetes.io/rewrite-target는 인그레서에 정의된 경로로 들어오는 요청을 rewrite-target에 설정된 경로로 전달한다. 예를 들어, Nginx 인그레스 컨트롤러로 /echo-hostname으로 접근하면 hostname-service에는 / 경로로 전달된다.  
단, rewrite-target은 /echo-hostname이라는 경로로 시작하는 모든 요청을 hostname-service의 / 로 전달한다.  
예를 들어 /echo-hostname/alice/bob이라는 경로로 요청을 보내도 똑같이  /로 전달된다.  


### 8.4 Nginx 인그레스 컨트롤러에 SSL/TLS 보안 연결 적용  
인그레스의 장점 중 하나는 쿠버네티스의 뒤쪽에 있는 디플로이먼트와 서비스가 아닌, 앞쪽에 있는 인그레스 컨트롤러에서 편리하게 SSL/TLS 보안 연결을 설정할 수 있다는 것이다.  
즉, 인그레스 컨트롤러 지점에서 인증서를 적용해 두면, 요청이 전달되는 애플리케이션에 대해 모두 인증서 처리를 할 수 있다.  
따라서 인그레스 컨트롤러가 보안 연결을 수립하기 위한 일졸의 관문(Gateway) 역할을 한다고 볼 수 있다.  

Nginx 인그레스 컨트롤러 또한 인증서를 통한 보안 연결 기능을 제공하기 때문에 어렵지 않게 보안 연결을 설정할 수 있다.  
보안 연결에 사용할 인증서와 비밀키 생성  
```
openssl req -x509 -nodes -days 365 -newkey rsa:2048 \  
-keyout tls.key -out tls.crt -subj "/CN=alicek106.example.com/0=alicek106  
```
/CN에는 Nginx 인그레서 컨트롤러에 접근하기 위한 Public DNS 이름을 입력해야 한다.  
위 예시는 Nginx 인그레스 컨트롤러와 연결된 서비스에  alicek106.example.com이라는 도메인으로 접근한다고 가정한 것이며,  
AWS에서 생성되어 동적인 도메인 이름을 할당받은 클래식 로드 밸런서라면 /CN=*.qp-northeast-2.elb.amazonaws.com처럼 사용하는 것도 가능하다.  

위 명령어로 tls.key라는 비밀키와 tls.crt라는 인증서가 생성된다. 이 파일들을 통해 tls 타입의 시크릿을 생성한다.  
``kubectl create secret tls tls-secret --key tls.key --cert tls.crt``  
...

인그레스 설정에 TLS 옵션을 추가해 적용한다.  
```
apiVersion: networking.k8s.io/v1beta1  
kind: Ingress  
metadata:  
  name: ingress-example  
  annotations:  
    nginx.ingress.kubernetes.io/rewrite-target: /  
    kubernetes.io/ingress.class: "nginx"  
spec:  
  tls:  
  - hosts:  
    - alicek106.example.com            # 여러분의 도메인 이름을 입력해야 합니다.  
    secretName: tls-secret  
  rules:  
  - host: alicek106.example.com          # 여러분의 도메인 이름을 입력해야 합니다.  
    http:  
      paths:  
      - path: /echo-hostname  
        backend:  
          serviceName: hostname-service  
          servicePort: 80  
```
spec.tls.hosts 항목에서는 보안 연결을 적용할 도메인 이름을, spec.tls.secretName은 앞서 생성했던 tls 타입의 시크릿 이름을 입력한다.  
이는 alicek106.example.com이라는 도메인 이름으로 접근하는 요청에 대해 tls-secret 시크릿의 인증서로 보안 연결을 수립하겠다는 뜻이다.  

인그레스를 생성한 뒤 Nginx 인그레스 컨트롤러로 요청을 보내고 데이터를 반환하는 것을 확인한다.  
``kubectl apply -f ingress-tls.yaml``  
``curl https://alicek106.example.com/echo-hostname -k``  
(curl -k 옵션은 신뢰할 수 없는 인증서로 보안 연결을 하기 위함)  


### 8.5 여러 개의 인그레스 컨트롤러 사용하기  
하나의 쿠버네티스 클러스터에서 반드시 하나의 인그레스 컨트롤러를 사용해야 하는 것은 아니다. Nginx 인그레스 컨트롤러는 기본적으로 nginx라는 이름의 클래스를 가지고 있으며, 이 설정을 변경함으로써 여러 개의 Nginx 인그레스 컨트롤러를 사용할 수 있고, 인그레스 규칙을 선택적으로 적용할 수도 있다.  

Nginx 인그레스 컨트롤러를 생성할 때 --ingress-class라는 옵션 및 alicek106-nginx라는 값을 설정하면, 이전에 생성했던 인그레스 규칙은 더 이상 Nginx 인그레스 컨트롤러에 적용되지 않는다.  
따라서 kubernetes.io/ingress.class 주석을 alicek106-nginx로 수정해줘야만 Nginx 인그레스 컨트롤러가 해당 인그레스의 규칙을 정상적으로 로드해 적용한다.  
```
apiVersion: networking.k8s.io/v1beta1  
kind: Ingress  
metadata:  
  name: ingress-example  
  annotations:  
    nginx.ingress.kubernetes.io/rewrite-target: /  
    kubernetes.io/ingress.class: "alicek106-nginx"  
```


### 참고자료  
1.[파란하늘의 지식창고](https://luvstudy.tistory.com/106)  